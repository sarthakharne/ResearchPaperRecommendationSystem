{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8301315,"sourceType":"datasetVersion","datasetId":4914193}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading the Nodes","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nfrom tqdm.notebook import tqdm\nimport gc\nfrom scipy import sparse, io\nfrom scipy.special import softmax\nimport os\n\nfrom collections import deque","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-05T00:25:10.514884Z","iopub.execute_input":"2024-05-05T00:25:10.515595Z","iopub.status.idle":"2024-05-05T00:25:12.244976Z","shell.execute_reply.started":"2024-05-05T00:25:10.515556Z","shell.execute_reply":"2024-05-05T00:25:12.243740Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df=pd.read_parquet(\"/kaggle/input/dataset-with-embeddings/cs_papers_wo_embeddings.parquet\")\ndf['categories'] = df['categories'].apply(lambda x: x.replace(', ', ''))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:25:12.247868Z","iopub.execute_input":"2024-05-05T00:25:12.248525Z","iopub.status.idle":"2024-05-05T00:25:14.084712Z","shell.execute_reply.started":"2024-05-05T00:25:12.248483Z","shell.execute_reply":"2024-05-05T00:25:14.083311Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"          id                                            authors  \\\n0  0704.0046                       I. Csiszar, F. Hiai, D. Petz   \n1  0704.0062  Rastislav \\v{S}r\\'amek, Bro\\v{n}a Brejov\\'a, T...   \n2  0704.0098                           Jack Raymond, David Saad   \n3  0704.0108                                       Sergey Gubin   \n4  0704.0213              Ketan D. Mulmuley Hariharan Narayanan   \n\n                                               title              categories  \\\n0  A limit relation for entropy and channel capac...  quant-ph cs.IT math.IT   \n1  On-line Viterbi Algorithm and Its Relationship...                   cs.DS   \n2  Sparsely-spread CDMA - a statistical mechanics...           cs.IT math.IT   \n3                              Reducing SAT to 2-SAT                   cs.CC   \n4  Geometric Complexity Theory V: On deciding non...                   cs.CC   \n\n                                            abstract update_date  degree  \\\n0    In a quantum mechanical model, Diosi, Feldma...  2009-11-13       1   \n1    In this paper, we introduce the on-line Vite...  2010-01-25       2   \n2    Sparse Code Division Multiple Access (CDMA),...  2009-11-13       1   \n3    Description of a polynomial time reduction o...  2007-05-23       5   \n4    This article has been withdrawn because it h...  2012-09-28       1   \n\n   num_citations  num_references  \n0              1               0  \n1              2               0  \n2              1               0  \n3              1               4  \n4              1               0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>authors</th>\n      <th>title</th>\n      <th>categories</th>\n      <th>abstract</th>\n      <th>update_date</th>\n      <th>degree</th>\n      <th>num_citations</th>\n      <th>num_references</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0704.0046</td>\n      <td>I. Csiszar, F. Hiai, D. Petz</td>\n      <td>A limit relation for entropy and channel capac...</td>\n      <td>quant-ph cs.IT math.IT</td>\n      <td>In a quantum mechanical model, Diosi, Feldma...</td>\n      <td>2009-11-13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0704.0062</td>\n      <td>Rastislav \\v{S}r\\'amek, Bro\\v{n}a Brejov\\'a, T...</td>\n      <td>On-line Viterbi Algorithm and Its Relationship...</td>\n      <td>cs.DS</td>\n      <td>In this paper, we introduce the on-line Vite...</td>\n      <td>2010-01-25</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0704.0098</td>\n      <td>Jack Raymond, David Saad</td>\n      <td>Sparsely-spread CDMA - a statistical mechanics...</td>\n      <td>cs.IT math.IT</td>\n      <td>Sparse Code Division Multiple Access (CDMA),...</td>\n      <td>2009-11-13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0704.0108</td>\n      <td>Sergey Gubin</td>\n      <td>Reducing SAT to 2-SAT</td>\n      <td>cs.CC</td>\n      <td>Description of a polynomial time reduction o...</td>\n      <td>2007-05-23</td>\n      <td>5</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0704.0213</td>\n      <td>Ketan D. Mulmuley Hariharan Narayanan</td>\n      <td>Geometric Complexity Theory V: On deciding non...</td>\n      <td>cs.CC</td>\n      <td>This article has been withdrawn because it h...</td>\n      <td>2012-09-28</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Utility Functions to make sure that only valid references are added","metadata":{}},{"cell_type":"code","source":"def get_paper_release_date_and_serial_no(paper_id):\n    yymm = None\n    try:\n        float(paper_id)\n        yymm = paper_id.split('.')[0]\n        serial_no = paper_id.split('.')[1]\n    except ValueError:\n        yymm = paper_id.split('/')[-1][:4]\n        serial_no = paper_id.split('/')[-1][4:]\n\n    if yymm.startswith('9'):\n        paper_yyyy = '19' + yymm[:2]\n    else:\n        paper_yyyy = '20' + yymm[:2]\n    paper_mm = yymm[-2:]\n        \n    return paper_yyyy + paper_mm, serial_no\n\ndef paper_1_came_before_paper_2(paper1_id, paper2_id):\n    paper1_yyyymm, paper1_sr_no = get_paper_release_date_and_serial_no(paper1_id)\n    paper2_yyyymm, paper2_sr_no = get_paper_release_date_and_serial_no(paper2_id)\n    \n    try:\n        if int(paper1_yyyymm) == int(paper2_yyyymm):\n            return paper1_sr_no < paper1_sr_no\n    except ValueError:\n        print(paper1_id, paper2_id)\n        print(paper1_yyyymm, paper2_yyyymm)\n        print(paper1_sr_no, paper2_sr_no)\n        \n        raise ValueError\n    \n    \n    return paper1_yyyymm < paper2_yyyymm\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:25:14.086806Z","iopub.execute_input":"2024-05-05T00:25:14.087649Z","iopub.status.idle":"2024-05-05T00:25:14.097736Z","shell.execute_reply.started":"2024-05-05T00:25:14.087604Z","shell.execute_reply":"2024-05-05T00:25:14.096787Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Node:\n    def __init__(self, node_id, authors=None, title=None, categories=None, abstract=None, embeddings=None, update_date=None, degree=None, num_citations=None, num_references=None):\n        self.id = str(node_id)\n        self.authors = self.parse_authors(authors)\n        self.title = self.remove_newlines(title)\n        self.categories = categories if categories else []\n        self.abstract = self.remove_newlines(abstract)\n        self.update_date = update_date\n        self.embeddings = embeddings\n        \n        self.degree = degree if degree is not None else 0\n        self.num_citations = num_citations if num_citations is not None else 0\n        self.num_references = num_references if num_references is not None else 0\n\n    # function to store authors in list format\n    def parse_authors(self, authors_string):\n        if authors_string:\n            authors_list = []\n            for author in authors_string.split(\" and \"):\n                authors_list.extend(author.split(\", \"))\n            return authors_list\n        else:\n            return []\n\n    # function to replace newline characters (\"\\n\") with an empty string\n    def remove_newlines(self, text):\n        return text.replace(\"\\n\", \" \")\n    \n    def get_title(self):\n        return self.title\n    \n    def get_id(self):\n        return self.id\n    \n    def get_info(self):\n        info = {   \n            'id': self.id,\n            'authors': ', '.join(self.authors),\n            'title': self.title,\n            'categories': self.categories,\n            'abstract': self.abstract,\n            'embedding': self.embeddings,\n            'update_date': self.update_date,\n            'degree': self.degree,\n            'num_citations': self.num_citations,\n            'num_references': self.num_references\n        }\n        \n        return info\n    \n    def update_degrees(self, degree, citations, references):\n        self.degree = degree\n        self.num_citations = citations\n        self.num_references = references\n    \nclass Graph:\n    def __init__(self):\n        self.nodes = {}\n        self.undirected_edges = {}\n        self.citation_edges = {}\n        self.reference_edges = {}\n        \n        self.node_degrees = {}\n        self.num_citations = {}\n        self.num_references = {}\n        \n        self.v_to_i = {}\n\n    # function to add nodes in the Graph data structure\n    def add_node(self, node_id, authors=None, title=None, categories=None, abstract=None, embedding=None, update_date=None, degree=None, num_citations=None, num_references=None):\n        node_id = str(node_id)\n        if node_id not in self.nodes:\n            self.nodes[node_id] = Node(node_id, authors, title, categories, abstract, embedding, update_date, degree, num_citations, num_references)\n\n    # function to add edges in the Graph data structure\n    def add_edge(self, node1, node2):\n        node1, node2 = str(node1), str(node2)\n        if paper_1_came_before_paper_2(node2, node1):\n            if node1 in self.nodes and node2 in self.nodes:\n                # conditions to add nodes to the edge lists of themselves and the neighbour node\n                if node1 not in self.undirected_edges:\n                    self.undirected_edges[node1] = []\n                    self.node_degrees[node1] = 0\n                if node2 not in self.undirected_edges:\n                    self.undirected_edges[node2] = []\n                    self.node_degrees[node2] = 0\n                if node2 not in self.undirected_edges[node1]:\n                    self.undirected_edges[node1].append(node2)\n                    self.node_degrees[node1] += 1\n                if node1 not in self.undirected_edges[node2]:\n                    self.undirected_edges[node2].append(node1)\n                    self.node_degrees[node2] += 1\n                \n                # when node1 references node2 i.e. referring\n                if node1 not in self.reference_edges:\n                    self.reference_edges[node1] = []\n                    self.num_references[node1] = 0\n                if node2 not in self.reference_edges[node1]:\n                    self.reference_edges[node1].append(node2)\n                    self.num_references[node1] += 1\n            \n                \n                # when node2 is referred by node1 i.e. citation\n                if node2 not in self.citation_edges:\n                    self.citation_edges[node2] = []\n                    self.num_citations[node2] = 0\n                if node1 not in self.citation_edges[node2]:\n                    self.citation_edges[node2].append(node1)\n                    self.num_citations[node2] += 1\n                \n    # update the degrees for all the nodes\n    def update_degrees(self):\n        for node_id, node_obj in tqdm(self.node_degrees.items(), total=len(list(self.node_degrees))):\n            try:\n                self.nodes[node_id].update_degrees(degree=self.node_degrees[node_id], citations=self.num_citations.get(node_id, 0), references=self.num_references.get(node_id, 0))\n            except KeyError as e:\n                raise KeyError(f\"KeyError occurred: {e}\")\n\n    # function to return list of nodes present in graph\n    def get_nodes(self):\n        return list(self.nodes)\n    \n    # get adjacency matrix based on the reference edges\n    def get_adjacency_matrix(self):\n        self.v_to_i = {}\n        for i, node_id in enumerate(list(self.nodes.keys())):\n            self.v_to_i[node_id] = i\n        \n        matrix = np.zeros((len(self.nodes.keys()), len(self.nodes.keys())), dtype=np.float16)\n        \n        for node_id in list(self.reference_edges.keys()):\n            adjacent_nodes = self.reference_edges[node_id]\n            \n            for adj_node in adjacent_nodes:\n                matrix[self.v_to_i[node_id], self.v_to_i[adj_node]] = 1\n\n        gc.collect()\n        \n        return matrix\n    \n    # get the adjacency matrix based of the citation edges\n    def get_adjacency_matrix_citation(self):\n        self.v_to_i = {}\n        for i, node_id in enumerate(list(self.nodes.keys())):\n            self.v_to_i[node_id] = i\n        \n        matrix = np.zeros((len(self.nodes.keys()), len(self.nodes.keys())), dtype=np.float16)\n        \n        for node_id in list(self.citation_edges.keys()):\n            adjacent_nodes = self.citation_edges[node_id]\n            \n            for adj_node in adjacent_nodes:\n                matrix[self.v_to_i[node_id], self.v_to_i[adj_node]] = 1\n\n        gc.collect()\n        \n        return matrix\n    \n    # return all the edges in the adjacency list format\n    def get_adjacency_list(self):\n        return self.undirected_edges, self.citation_edges, self.reference_edges\n    \n    # given the title of the paper, return the node\n    def get_node_by_title(self, title):\n        \"\"\"\n        Return the node corresponding to the research paper with the given title.\n        If not found, return None.\n        \"\"\"\n        \n        for node in self.nodes:\n            # print(node.id,title)\n            if self.nodes[node].get_title()==title:\n                return self.nodes[node].get_info()\n        return None\n    \n    # utility function to remove all the nodes with zero degree\n    def remove_isolated_nodes(self):\n        node_ids = list(self.nodes.keys())\n        for id in tqdm(node_ids):\n            if self.nodes[id].degree == 0:\n                del self.nodes[id]\n\n    # function to return list of edges present in graph based on the undirected edges\n    def get_edge_list(self):\n        edge_list = []\n        for node, connected_nodes in tqdm(self.undirected_edges.items(), total=len(list(self.undirected_edges.keys()))):\n            for connected_node in connected_nodes:\n                edge_list.append((node, connected_node))\n        return edge_list\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:25:14.100671Z","iopub.execute_input":"2024-05-05T00:25:14.101396Z","iopub.status.idle":"2024-05-05T00:25:14.135717Z","shell.execute_reply.started":"2024-05-05T00:25:14.101354Z","shell.execute_reply":"2024-05-05T00:25:14.133420Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"graph = Graph()\n\n# make the graph based on the node dataframe\nfor index, row in tqdm(df.iterrows(), total=df.shape[0]):\n    node_id = str(row['id'])\n    authors = row['authors']\n    title = row['title']\n    categories = row['categories']\n    abstract = row['abstract']\n    embedding = None if 'embeddings' not in df.columns else row['embeddings']\n    update_date = row['update_date']\n    degree = row['degree']\n    num_citations = row['num_citations']\n    num_references = row['num_references']\n    \n\n    graph.add_node(node_id, authors=authors, title=title, categories=categories, abstract=abstract, embedding=embedding, update_date=update_date, degree=degree, num_citations=num_citations, num_references=num_references)\n\nn_nodes = len(graph.nodes)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:25:14.137388Z","iopub.execute_input":"2024-05-05T00:25:14.137848Z","iopub.status.idle":"2024-05-05T00:25:24.497081Z","shell.execute_reply.started":"2024-05-05T00:25:14.137805Z","shell.execute_reply":"2024-05-05T00:25:24.495687Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/88281 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4df8bd3a55e8423d879ba5a13de9fbf2"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"19"},"metadata":{}}]},{"cell_type":"markdown","source":"# Creating the Graph","metadata":{}},{"cell_type":"code","source":"# load the reference edges\ncitation_data = pd.read_parquet(\"/kaggle/input/dataset-with-embeddings/reference_edges.parquet\")","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:25:24.498715Z","iopub.execute_input":"2024-05-05T00:25:24.499174Z","iopub.status.idle":"2024-05-05T00:25:24.647654Z","shell.execute_reply.started":"2024-05-05T00:25:24.499145Z","shell.execute_reply":"2024-05-05T00:25:24.646613Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# # to add self edges\n# paper_ids = list(citation_data[\"id\"])\n# for i in tqdm(range(citation_data.shape[0])):\n#     refer_list = list(citation_data.loc[i, 'refers'])\n#     refer_list.append(citation_data.loc[i, 'id'])\n#     citation_data.loc[i, 'refers'] = np.array(refer_list)\n#     break","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:25:24.649079Z","iopub.execute_input":"2024-05-05T00:25:24.649595Z","iopub.status.idle":"2024-05-05T00:25:24.655685Z","shell.execute_reply.started":"2024-05-05T00:25:24.649548Z","shell.execute_reply":"2024-05-05T00:25:24.654312Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# add edges to the graph\nfor i, row in tqdm(citation_data.iterrows(), total=citation_data.shape[0]):\n    source_id = row['paper_id']\n    target_ids = row['refers_to']\n    for target_id in target_ids: \n        graph.add_edge(source_id, target_id)\n        \ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:25:24.657371Z","iopub.execute_input":"2024-05-05T00:25:24.658666Z","iopub.status.idle":"2024-05-05T00:25:36.299650Z","shell.execute_reply.started":"2024-05-05T00:25:24.658614Z","shell.execute_reply":"2024-05-05T00:25:36.298467Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/66877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24a7f8384d7d4755b8ec5d3fdfaa759c"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"19"},"metadata":{}}]},{"cell_type":"code","source":"adj_mat = graph.get_adjacency_matrix()\nadj_mat.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:25:36.301397Z","iopub.execute_input":"2024-05-05T00:25:36.301880Z","iopub.status.idle":"2024-05-05T00:25:37.425853Z","shell.execute_reply.started":"2024-05-05T00:25:36.301840Z","shell.execute_reply":"2024-05-05T00:25:37.424636Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(88281, 88281)"},"metadata":{}}]},{"cell_type":"code","source":"def pagerank(adjacency, probs=None, n_iters=20, resid=0.4):\n    \"\"\"\n    Args:\n        adjacency - sparse matrix\n        probs - array of initial random jump probabilities.\n    \"\"\"\n    n_nodes, _ = adjacency.shape\n    adjacency = sparse.lil_array(adjacency.astype(bool)).astype(float)\n    # set 'sinks' to have random transitions\n    out_degrees = adjacency.sum(1)\n    transitions = adjacency*(1/out_degrees[:, np.newaxis])\n    transitions = transitions.T\n    transitions = sparse.csc_array(transitions)\n    # initial rank: all equal\n    # adjacency[i, j] indicates an edge from i to j \n    if probs is None:\n        probs = np.ones(n_nodes)/n_nodes\n        probs = probs[:, np.newaxis]\n    # run power iterations\n    for _ in tqdm(range(n_iters)):\n        probs = resid*transitions.dot(probs) + (1 - resid)*(1/n_nodes)\n        probs /= probs.sum()\n        \n    # return the stationary probability, and the transition matrix\n    return probs, transitions","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:25:37.430375Z","iopub.execute_input":"2024-05-05T00:25:37.431444Z","iopub.status.idle":"2024-05-05T00:25:37.439653Z","shell.execute_reply.started":"2024-05-05T00:25:37.431399Z","shell.execute_reply":"2024-05-05T00:25:37.438388Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"resid = 0.95","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:25:37.441434Z","iopub.execute_input":"2024-05-05T00:25:37.441820Z","iopub.status.idle":"2024-05-05T00:25:37.456794Z","shell.execute_reply.started":"2024-05-05T00:25:37.441789Z","shell.execute_reply":"2024-05-05T00:25:37.455494Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"out = pagerank(adj_mat, n_iters=10000, resid=resid)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:25:37.458518Z","iopub.execute_input":"2024-05-05T00:25:37.458973Z","iopub.status.idle":"2024-05-05T00:26:44.544927Z","shell.execute_reply.started":"2024-05-05T00:25:37.458933Z","shell.execute_reply":"2024-05-05T00:26:44.543534Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2117850111.py:11: RuntimeWarning: divide by zero encountered in divide\n  transitions = adjacency*(1/out_degrees[:, np.newaxis])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e09c19320d6c4ba0aedbcb09f26ddb8c"}},"metadata":{}}]},{"cell_type":"code","source":"# get n closest papers using beam search\ndef get_n_closest_papers_via_beam_search(n, n_beams, transition_matrix, stationary_probability, graph, paper_id=None, paper_index=None, discount_factor=0.8, reverse_traversal=True):\n    if paper_id is None and paper_index is None:\n        raise Exception(\"paper_id and paper_index both cannot be None\")\n    if paper_id is not None:\n        paper_index = graph.v_to_i[paper_id]\n    if not reverse_traversal:\n        transition_matrix = transition_matrix.T\n        \n    # set with all the best papers\n    best_papers_set = {}\n    # set the input index as the current index\n    curr_paper_index = paper_index\n    # number of papers explored\n    papers_explored = 0\n    \n    # run until we have the required number of papers\n    while len(best_papers_set) <= n:\n        # set containing papers from the current beam\n        beam_set = {}\n        # calculate the probs to the next paper taking a col (row in this implementation) from the transpose of the matrix\n        probs = (discount_factor**(len(best_papers_set)//n_beams))*(resid*transition_matrix[curr_paper_index:curr_paper_index+1, :].toarray() + (1 - resid)*(1/n_nodes))\n        # multiply the markov jump probability with the page rank\n        probs_real = np.squeeze(probs)*stationary_probability\n        # get the indices with the highes probabilities\n        ind = np.argpartition(probs_real, -100)\n        ind = ind[np.argsort(probs_real[ind])]\n        \n        # add papers till the beam set is full starting from the last paper\n        curr_ind = -1\n        while len(beam_set) <= n_beams:\n            if ind[curr_ind] not in best_papers_set and ind[curr_ind] != curr_paper_index:\n                beam_set[ind[curr_ind]] = probs_real[ind[curr_ind]]\n            curr_ind -= 1\n        \n        # add beam set to the set to be returned\n        keys = list(beam_set.keys())\n        keys.reverse()\n        best_papers_set = {**best_papers_set, **beam_set}\n        curr_paper_index = list(best_papers_set.keys())[papers_explored]\n        papers_explored += 1\n        \n    return best_papers_set\n\ndef get_n_best_papers_page_rank(n, n_beams, transition_matrix, stationary_probability, graph, paper_id=None, paper_index=None, discount_factor=0.8, bwd_percent=0.8):\n    fwd_papers = get_n_closest_papers_via_beam_search(int(n*bwd_percent), n_beams, transition_matrix, stationary_probability, graph, paper_id, paper_index, discount_factor, reverse_traversal=True)\n    bwd_papers = get_n_closest_papers_via_beam_search(n - int(n*bwd_percent), n_beams, transition_matrix, stationary_probability, graph, paper_id, paper_index, discount_factor, reverse_traversal=False)\n    \n    return {**fwd_papers, **bwd_papers}\n\n\n\n# get_n_best_papers(n=10, n_beams=2, transition_matrix, stationary_probability, graph, paper_id=None, paper_index=None, discount_factor=0.8, reverse_traversal=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:26:44.546108Z","iopub.execute_input":"2024-05-05T00:26:44.546434Z","iopub.status.idle":"2024-05-05T00:26:44.560340Z","shell.execute_reply.started":"2024-05-05T00:26:44.546409Z","shell.execute_reply":"2024-05-05T00:26:44.559040Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"papers_read = ['1512.03385', '1706.03762', '1312.5602']\n\nclosest_papers = {}\nfor paper_id in papers_read:\n    closest_papers = {**closest_papers, **get_n_best_papers_page_rank(n=5, n_beams=3, transition_matrix=out[1], stationary_probability=np.squeeze(out[0]), graph=graph, paper_id=paper_id)}","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:26:44.561380Z","iopub.execute_input":"2024-05-05T00:26:44.561711Z","iopub.status.idle":"2024-05-05T00:26:44.667063Z","shell.execute_reply.started":"2024-05-05T00:26:44.561683Z","shell.execute_reply":"2024-05-05T00:26:44.665828Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"emb_df = pd.read_parquet('/kaggle/input/dataset-with-embeddings/embeddings.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:26:44.669360Z","iopub.execute_input":"2024-05-05T00:26:44.669715Z","iopub.status.idle":"2024-05-05T00:26:49.771663Z","shell.execute_reply.started":"2024-05-05T00:26:44.669688Z","shell.execute_reply":"2024-05-05T00:26:49.770665Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def get_cosine_scores(embed_df, papers_read):\n    norm_embeds = np.array(embed_df)/np.linalg.norm(np.array(embed_df), axis=0)\n    \n    embedding = np.array(embed_df[df['id'].isin(papers_read)])\n    norm_paper_embeds = (embedding/np.linalg.norm(embedding, axis=0))\n    \n    sim_df = norm_embeds.dot(norm_paper_embeds.T)\n    sim_df = sim_df.max(axis=1)\n    \n    return sim_df","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:26:49.774725Z","iopub.execute_input":"2024-05-05T00:26:49.775232Z","iopub.status.idle":"2024-05-05T00:26:49.781464Z","shell.execute_reply.started":"2024-05-05T00:26:49.775170Z","shell.execute_reply":"2024-05-05T00:26:49.780472Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"sim_df = get_cosine_scores(emb_df, papers_read)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:26:49.782935Z","iopub.execute_input":"2024-05-05T00:26:49.783874Z","iopub.status.idle":"2024-05-05T00:26:50.353660Z","shell.execute_reply.started":"2024-05-05T00:26:49.783838Z","shell.execute_reply":"2024-05-05T00:26:50.352308Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def get_final_recs(closest_papers, sim_df, alpha=0.8):\n    normalised_probs = np.array(list(closest_papers.values()))\n    normalised_probs = normalised_probs/normalised_probs.sum()\n    \n    best_sim_df = sim_df\n    best_sim_df[list(closest_papers.keys())] = best_sim_df[list(closest_papers.keys())]/best_sim_df[list(closest_papers.keys())].sum()\n    \n    final_papers = {}\n    for id, paper in enumerate(closest_papers):\n    #     selected_paper_id = list(closest_papers.keys())[paper]\n        selected_paper_prob = alpha * normalised_probs[id] + (1 - alpha) * best_sim_df[paper]\n        final_papers[paper] = selected_paper_prob\n        \n    best_paper_indices = np.flip(np.argsort(np.array(list(final_papers.values()))))\n    \n    return final_papers, best_paper_indices","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:26:50.355826Z","iopub.execute_input":"2024-05-05T00:26:50.356839Z","iopub.status.idle":"2024-05-05T00:26:50.367172Z","shell.execute_reply.started":"2024-05-05T00:26:50.356788Z","shell.execute_reply":"2024-05-05T00:26:50.365606Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"final_papers, best_paper_indices = get_final_recs(closest_papers, sim_df, 0.5)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T00:26:50.369738Z","iopub.execute_input":"2024-05-05T00:26:50.371054Z","iopub.status.idle":"2024-05-05T00:26:50.381482Z","shell.execute_reply.started":"2024-05-05T00:26:50.370988Z","shell.execute_reply":"2024-05-05T00:26:50.379867Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for id in best_paper_indices:\n    paper_index = list(final_papers.keys())[id]\n    df_row=df.iloc[paper_index]\n    print(df_row['id'])\n    print(df_row[\"title\"])\n    print(df_row[\"abstract\"])\n    print(\"Citations\", df_row[\"num_citations\"])\n    print(\"References\", df_row[\"num_references\"])\n    print(\"Degree\", df_row[\"degree\"])\n    print()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-05T00:26:50.384818Z","iopub.execute_input":"2024-05-05T00:26:50.386162Z","iopub.status.idle":"2024-05-05T00:26:50.407107Z","shell.execute_reply.started":"2024-05-05T00:26:50.386100Z","shell.execute_reply":"2024-05-05T00:26:50.405673Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"1408.5093\nCaffe: Convolutional Architecture for Fast Feature Embedding\n  Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU ($\\approx$ 2.5 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia. \nCitations 1027\nReferences 2\nDegree 1029\n\n1502.05477\nTrust Region Policy Optimization\n  We describe an iterative procedure for optimizing policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified procedure, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is similar to natural policy gradient methods and is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters. \nCitations 76\nReferences 3\nDegree 79\n\n1308.0850\nGenerating Sequences With Recurrent Neural Networks\n  This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles. \nCitations 515\nReferences 1\nDegree 516\n\n1312.4400\nNetwork In Network\n  We propose a novel deep network structure called \"Network In Network\" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets. \nCitations 419\nReferences 7\nDegree 426\n\n1507.00814\nIncentivizing Exploration In Reinforcement Learning With Deep Predictive   Models\n  Achieving efficient and scalable exploration in complex domains poses a major challenge in reinforcement learning. While Bayesian and PAC-MDP approaches to the exploration problem offer strong formal guarantees, they are often impractical in higher dimensions due to their reliance on enumerating the state-action space. Hence, exploration in complex domains is often performed with simple epsilon-greedy methods. In this paper, we consider the challenging Atari games domain, which requires processing raw pixel inputs and delayed rewards. We evaluate several more sophisticated exploration strategies, including Thompson sampling and Boltzman exploration, and propose a new exploration method based on assigning exploration bonuses from a concurrently learned model of the system dynamics. By parameterizing our learned model with a neural network, we are able to develop a scalable and efficient approach to exploration bonuses that can be applied to tasks with complex, high-dimensional state spaces. In the Atari domain, our method provides the most consistent improvement across a range of games that pose a major challenge for prior methods. In addition to raw game-scores, we also develop an AUC-100 metric for the Atari Learning domain to evaluate the impact of exploration on this benchmark. \nCitations 59\nReferences 1\nDegree 60\n\n1506.02438\nHigh-Dimensional Continuous Control Using Generalized Advantage   Estimation\n  Policy gradient methods are an appealing approach in reinforcement learning because they directly optimize the cumulative reward and can straightforwardly be used with nonlinear function approximators such as neural networks. The two main challenges are the large number of samples typically required, and the difficulty of obtaining stable and steady improvement despite the nonstationarity of the incoming data. We address the first challenge by using value functions to substantially reduce the variance of policy gradient estimates at the cost of some bias, with an exponentially-weighted estimator of the advantage function that is analogous to TD(lambda). We address the second challenge by using trust region optimization procedure for both the policy and the value function, which are represented by neural networks.   Our approach yields strong empirical results on highly challenging 3D locomotion tasks, learning running gaits for bipedal and quadrupedal simulated robots, and learning a policy for getting the biped to stand up from starting out lying on the ground. In contrast to a body of prior work that uses hand-crafted policy representations, our neural network policies map directly from raw kinematics to joint torques. Our algorithm is fully model-free, and the amount of simulated experience required for the learning tasks on 3D bipeds corresponds to 1-2 weeks of real time. \nCitations 146\nReferences 1\nDegree 147\n\n1302.4389\nMaxout Networks\n  We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN. \nCitations 141\nReferences 2\nDegree 143\n\n1409.0473\nNeural Machine Translation by Jointly Learning to Align and Translate\n  Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition. \nCitations 1471\nReferences 2\nDegree 1473\n\n1605.02097\nViZDoom: A Doom-based AI Research Platform for Visual Reinforcement   Learning\n  The recent advances in deep neural networks have led to effective vision-based reinforcement learning methods that have been employed to obtain human-level controllers in Atari 2600 games from pixel data. Atari 2600 games, however, do not resemble real-world tasks since they involve non-realistic 2D environments and the third-person perspective. Here, we propose a novel test-bed platform for reinforcement learning research from raw visual information which employs the first-person perspective in a semi-realistic 3D world. The software, called ViZDoom, is based on the classical first-person shooter video game, Doom. It allows developing bots that play the game using the screen buffer. ViZDoom is lightweight, fast, and highly customizable via a convenient mechanism of user scenarios. In the experimental part, we test the environment by trying to learn bots for two scenarios: a basic move-and-shoot task and a more complex maze-navigation problem. Using convolutional deep neural networks with Q-learning and experience replay, for both scenarios, we were able to train competent bots, which exhibit human-like behaviors. The results confirm the utility of ViZDoom as an AI research platform and imply that visual reinforcement learning in 3D realistic first-person perspective environments is feasible. \nCitations 30\nReferences 1\nDegree 31\n\n1602.07261\nInception-v4, Inception-ResNet and the Impact of Residual Connections on   Learning\n  Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question of whether there are any benefit in combining the Inception architecture with residual connections. Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4, we achieve 3.08 percent top-5 error on the test set of the ImageNet classification (CLS) challenge \nCitations 211\nReferences 4\nDegree 215\n\n1509.02971\nContinuous control with deep reinforcement learning\n  We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs. \nCitations 445\nReferences 6\nDegree 451\n\n1603.04119\nExploratory Gradient Boosting for Reinforcement Learning in Complex   Domains\n  High-dimensional observations and complex real-world dynamics present major challenges in reinforcement learning for both function approximation and exploration. We address both of these challenges with two complementary techniques: First, we develop a gradient-boosting style, non-parametric function approximator for learning on $Q$-function residuals. And second, we propose an exploration strategy inspired by the principles of state abstraction and information acquisition under uncertainty. We demonstrate the empirical effectiveness of these techniques, first, as a preliminary check, on two standard tasks (Blackjack and $n$-Chain), and then on two much larger and more realistic tasks with high-dimensional observation spaces. Specifically, we introduce two benchmarks built within the game Minecraft where the observations are pixel arrays of the agent's visual field. A combination of our two algorithmic techniques performs competitively on the standard reinforcement-learning tasks while consistently and substantially outperforming baselines on the two tasks with high-dimensional observation spaces. The new function approximator, exploration strategy, and evaluation benchmarks are each of independent interest in the pursuit of reinforcement-learning methods that scale to real-world domains. \nCitations 7\nReferences 4\nDegree 11\n\n1406.1078\nLearning Phrase Representations using RNN Encoder-Decoder for   Statistical Machine Translation\n  In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases. \nCitations 720\nReferences 2\nDegree 722\n\n1412.3555\nEmpirical Evaluation of Gated Recurrent Neural Networks on Sequence   Modeling\n  In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM. \nCitations 610\nReferences 5\nDegree 615\n\n1609.03499\nWaveNet: A Generative Model for Raw Audio\n  This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition. \nCitations 365\nReferences 7\nDegree 372\n\n1601.06759\nPixel Recurrent Neural Networks\n  Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two-dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNet dataset. Samples generated from the model appear crisp, varied and globally coherent. \nCitations 195\nReferences 7\nDegree 202\n\n1511.05952\nPrioritized Experience Replay\n  Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 41 out of 49 games. \nCitations 163\nReferences 6\nDegree 169\n\n1707.06347\nProximal Policy Optimization Algorithms\n  We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a \"surrogate\" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time. \nCitations 324\nReferences 7\nDegree 331\n\n1803.09017\nStyle Tokens: Unsupervised Style Modeling, Control and Transfer in   End-to-End Speech Synthesis\n  In this work, we propose \"global style tokens\" (GSTs), a bank of embeddings that are jointly trained within Tacotron, a state-of-the-art end-to-end speech synthesis system. The embeddings are trained with no explicit labels, yet learn to model a large range of acoustic expressiveness. GSTs lead to a rich set of significant results. The soft interpretable \"labels\" they generate can be used to control synthesis in novel ways, such as varying speed and speaking style - independently of the text content. They can also be used for style transfer, replicating the speaking style of a single audio clip across an entire long-form text corpus. When trained on noisy, unlabeled found data, GSTs learn to factorize noise and speaker identity, providing a path towards highly scalable but robust speech synthesis. \nCitations 10\nReferences 7\nDegree 17\n\n1805.08318\nSelf-Attention Generative Adversarial Networks\n  In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN achieves the state-of-the-art results, boosting the best published Inception score from 36.8 to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape. \nCitations 56\nReferences 7\nDegree 63\n\n1811.02050\nLeveraging Weakly Supervised Data to Improve End-to-End Speech-to-Text   Translation\n  End-to-end Speech Translation (ST) models have many potential advantages when compared to the cascade of Automatic Speech Recognition (ASR) and text Machine Translation (MT) models, including lowered inference latency and the avoidance of error compounding. However, the quality of end-to-end ST is often limited by a paucity of training data, since it is difficult to collect large parallel corpora of speech and translated transcript pairs. Previous studies have proposed the use of pre-trained components and multi-task learning in order to benefit from weakly supervised training data, such as speech-to-transcript or text-to-foreign-text pairs. In this paper, we demonstrate that using pre-trained MT or text-to-speech (TTS) synthesis models to convert weakly supervised data into speech-to-translation pairs for ST training can be more effective than multi-task learning. Furthermore, we demonstrate that a high quality end-to-end ST model can be trained using only weakly supervised datasets, and that synthetic data sourced from unlabeled monolingual text or speech can be used to improve performance. Finally, we discuss methods for avoiding overfitting to synthetic speech with a quantitative ablation study. \nCitations 0\nReferences 5\nDegree 5\n\n1505.00521\nReinforcement Learning Neural Turing Machines - Revised\n  The Neural Turing Machine (NTM) is more expressive than all previously considered models because of its external memory. It can be viewed as a broader effort to use abstract external Interfaces and to learn a parametric model that interacts with them.   The capabilities of a model can be extended by providing it with proper Interfaces that interact with the world. These external Interfaces include memory, a database, a search engine, or a piece of software such as a theorem verifier. Some of these Interfaces are provided by the developers of the model. However, many important existing Interfaces, such as databases and search engines, are discrete.   We examine feasibility of learning models to interact with discrete Interfaces. We investigate the following discrete Interfaces: a memory Tape, an input Tape, and an output Tape. We use a Reinforcement Learning algorithm to train a neural network that interacts with such Interfaces to solve simple algorithmic tasks. Our Interfaces are expressive enough to make our model Turing complete. \nCitations 90\nReferences 8\nDegree 98\n\n1711.00279\nParaphrase Generation with Deep Reinforcement Learning\n  Automatic generation of paraphrases from a given sentence is an important yet challenging task in natural language processing (NLP), and plays a key role in a number of applications such as question answering, search, and dialogue. In this paper, we present a deep reinforcement learning approach to paraphrase generation. Specifically, we propose a new framework for the task, which consists of a \\textit{generator} and an \\textit{evaluator}, both of which are learned from data. The generator, built as a sequence-to-sequence learning model, can produce paraphrases given a sentence. The evaluator, constructed as a deep matching model, can judge whether two sentences are paraphrases of each other. The generator is first trained by deep learning and then further fine-tuned by reinforcement learning in which the reward is given by the evaluator. For the learning of the evaluator, we propose two methods based on supervised learning and inverse reinforcement learning respectively, depending on the type of available training data. Empirical study shows that the learned evaluator can guide the generator to produce more accurate paraphrases. Experimental results demonstrate the proposed models (the generators) outperform the state-of-the-art methods in paraphrase generation in both automatic evaluation and human evaluation. \nCitations 8\nReferences 2\nDegree 10\n\n1611.02779\nRL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning\n  Deep reinforcement learning (deep RL) has been successful in learning sophisticated behaviors automatically; however, the learning process requires a huge number of trials. In contrast, animals can learn new tasks in just a few trials, benefiting from their prior knowledge about the world. This paper seeks to bridge this gap. Rather than designing a \"fast\" reinforcement learning algorithm, we propose to represent it as a recurrent neural network (RNN) and learn it from data. In our proposed method, RL$^2$, the algorithm is encoded in the weights of the RNN, which are learned slowly through a general-purpose (\"slow\") RL algorithm. The RNN receives all information a typical RL algorithm would receive, including observations, actions, rewards, and termination flags; and it retains its state across episodes in a given Markov Decision Process (MDP). The activations of the RNN store the state of the \"fast\" RL algorithm on the current (previously unseen) MDP. We evaluate RL$^2$ experimentally on both small-scale and large-scale problems. On the small-scale side, we train it to solve randomly generated multi-arm bandit problems and finite MDPs. After RL$^2$ is trained, its performance on new MDPs is close to human-designed algorithms with optimality guarantees. On the large-scale side, we test RL$^2$ on a vision-based navigation task and show that it scales up to high-dimensional problems. \nCitations 71\nReferences 24\nDegree 95\n\n1707.03141\nA Simple Neural Attentive Meta-Learner\n  Deep neural networks excel in regimes with large amounts of data, but tend to struggle when data is scarce or when they need to adapt quickly to changes in the task. In response, recent work in meta-learning proposes training a meta-learner on a distribution of similar tasks, in the hopes of generalization to novel but related tasks by learning a high-level strategy that captures the essence of the problem it is asked to solve. However, many recent meta-learning approaches are extensively hand-designed, either using architectures specialized to a particular application, or hard-coding algorithmic components that constrain how the meta-learner solves the task. We propose a class of simple and generic meta-learner architectures that use a novel combination of temporal convolutions and soft attention; the former to aggregate information from past experience and the latter to pinpoint specific pieces of information. In the most extensive set of meta-learning experiments to date, we evaluate the resulting Simple Neural AttentIve Learner (or SNAIL) on several heavily-benchmarked tasks. On all tasks, in both supervised and reinforcement learning, SNAIL attains state-of-the-art performance by significant margins. \nCitations 30\nReferences 7\nDegree 37\n\n1609.02993\nEpisodic Exploration for Deep Deterministic Policies: An Application to   StarCraft Micromanagement Tasks\n  We consider scenarios from the real-time strategy game StarCraft as new benchmarks for reinforcement learning algorithms. We propose micromanagement tasks, which present the problem of the short-term, low-level control of army members during a battle. From a reinforcement learning point of view, these scenarios are challenging because the state-action space is very large, and because there is no obvious feature representation for the state-action evaluation function. We describe our approach to tackle the micromanagement scenarios with deep neural network controllers from raw state features given by the game engine. In addition, we present a heuristic reinforcement learning algorithm which combines direct exploration in the policy space and backpropagation. This algorithm allows for the collection of traces for learning using deterministic policies, which appears much more efficient than, for example, {\\epsilon}-greedy exploration. Experiments show that with this algorithm, we successfully learn non-trivial strategies for scenarios with armies of up to 15 agents, where both Q-learning and REINFORCE struggle. \nCitations 26\nReferences 7\nDegree 33\n\n1310.1531\nDeCAF: A Deep Convolutional Activation Feature for Generic Visual   Recognition\n  We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms. \nCitations 182\nReferences 2\nDegree 184\n\n1611.04717\n#Exploration: A Study of Count-Based Exploration for Deep Reinforcement   Learning\n  Count-based exploration algorithms are known to perform near-optimally when used in conjunction with tabular reinforcement learning (RL) methods for solving small discrete Markov decision processes (MDPs). It is generally thought that count-based methods cannot be applied in high-dimensional state spaces, since most states will only occur once. Recent deep RL exploration strategies are able to deal with high-dimensional continuous state spaces through complex heuristics, often relying on optimism in the face of uncertainty or intrinsic motivation. In this work, we describe a surprising finding: a simple generalization of the classic count-based approach can reach near state-of-the-art performance on various high-dimensional and/or continuous deep RL benchmarks. States are mapped to hash codes, which allows to count their occurrences with a hash table. These counts are then used to compute a reward bonus according to the classic count-based exploration theory. We find that simple hash functions can achieve surprisingly good results on many challenging tasks. Furthermore, we show that a domain-dependent learned hash code may further improve these results. Detailed analysis reveals important aspects of a good hash function: 1) having appropriate granularity and 2) encoding information relevant to solving the MDP. This exploration strategy achieves near state-of-the-art performance on both continuous control tasks and Atari 2600 games, hence providing a simple yet powerful baseline for solving MDPs that require considerable exploration. \nCitations 17\nReferences 7\nDegree 24\n\n1901.00707\nFeature reinforcement with word embedding and parsing information in   neural TTS\n  In this paper, we propose a feature reinforcement method under the sequence-to-sequence neural text-to-speech (TTS) synthesis framework. The proposed method utilizes the multiple input encoder to take three levels of text information, i.e., phoneme sequence, pre-trained word embedding, and grammatical structure of sentences from parser as the input feature for the neural TTS system. The added word and sentence level information can be viewed as the feature based pre-training strategy, which clearly enhances the model generalization ability. The proposed method not only improves the system robustness significantly but also improves the synthesized speech to near recording quality in our experiments for out-of-domain text. \nCitations 0\nReferences 5\nDegree 5\n\n1107.2490\nTowards Optimal One Pass Large Scale Learning with Averaged Stochastic   Gradient Descent\n  For large scale learning problems, it is desirable if we can obtain the optimal model parameters by going through the data in only one pass. Polyak and Juditsky (1992) showed that asymptotically the test performance of the simple average of the parameters obtained by stochastic gradient descent (SGD) is as good as that of the parameters which minimize the empirical cost. However, to our knowledge, despite its optimal asymptotic convergence rate, averaged SGD (ASGD) received little attention in recent research on large scale learning. One possible reason is that it may take a prohibitively large number of training samples for ASGD to reach its asymptotic region for most real problems. In this paper, we present a finite sample analysis for the method of Polyak and Juditsky (1992). Our analysis shows that it indeed usually takes a huge number of samples for ASGD to reach its asymptotic region for improperly chosen learning rate. More importantly, based on our analysis, we propose a simple way to properly set learning rate so that it takes a reasonable amount of data for ASGD to reach its asymptotic region. We compare ASGD using our proposed learning rate with other well known algorithms for training large scale linear classifiers. The experiments clearly show the superiority of ASGD. \nCitations 22\nReferences 0\nDegree 22\n\n1108.3298\nA Machine Learning Perspective on Predictive Coding with PAQ\n  PAQ8 is an open source lossless data compression algorithm that currently achieves the best compression rates on many benchmarks. This report presents a detailed description of PAQ8 from a statistical machine learning perspective. It shows that it is possible to understand some of the modules of PAQ8 and use this understanding to improve the method. However, intuitive statistical explanations of the behavior of other modules remain elusive. We hope the description in this report will be a starting point for discussions that will increase our understanding, lead to improvements to PAQ8, and facilitate a transfer of knowledge from PAQ8 to other machine learning methods, such a recurrent neural networks and stochastic memoizers. Finally, the report presents a broad range of new applications of PAQ to machine learning tasks including language modeling and adaptive text prediction, adaptive game playing, classification, and compression using features from the field of deep learning. \nCitations 1\nReferences 0\nDegree 1\n\n1712.05884\nNatural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram   Predictions\n  This paper describes Tacotron 2, a neural network architecture for speech synthesis directly from text. The system is composed of a recurrent sequence-to-sequence feature prediction network that maps character embeddings to mel-scale spectrograms, followed by a modified WaveNet model acting as a vocoder to synthesize timedomain waveforms from those spectrograms. Our model achieves a mean opinion score (MOS) of $4.53$ comparable to a MOS of $4.58$ for professionally recorded speech. To validate our design choices, we present ablation studies of key components of our system and evaluate the impact of using mel spectrograms as the input to WaveNet instead of linguistic, duration, and $F_0$ features. We further demonstrate that using a compact acoustic intermediate representation enables significant simplification of the WaveNet architecture. \nCitations 27\nReferences 5\nDegree 32\n\n1207.0580\nImproving neural networks by preventing co-adaptation of feature   detectors\n  When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This \"overfitting\" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random \"dropout\" gives big improvements on many benchmark tasks and sets new records for speech and object recognition. \nCitations 661\nReferences 0\nDegree 661\n\n1710.07654\nDeep Voice 3: Scaling Text-to-Speech with Convolutional Sequence   Learning\n  We present Deep Voice 3, a fully-convolutional attention-based neural text-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training ten times faster. We scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers. In addition, we identify common error modes of attention-based speech synthesis networks, demonstrate how to mitigate them, and compare several different waveform synthesis methods. We also describe how to scale inference to ten million queries per day on one single-GPU server. \nCitations 10\nReferences 3\nDegree 13\n\n1702.03920\nCognitive Mapping and Planning for Visual Navigation\n  We introduce a neural architecture for navigation in novel environments. Our proposed architecture learns to map from first-person views and plans a sequence of actions towards goals in the environment. The Cognitive Mapper and Planner (CMP) is based on two key ideas: a) a unified joint architecture for mapping and planning, such that the mapping is driven by the needs of the task, and b) a spatial memory with the ability to plan given an incomplete set of observations about the world. CMP constructs a top-down belief map of the world and applies a differentiable neural net planner to produce the next action at each time step. The accumulated belief of the world enables the agent to track visited regions of the environment. We train and test CMP on navigation problems in simulation environments derived from scans of real world buildings. Our experiments demonstrate that CMP outperforms alternate learning-based architectures, as well as, classical mapping and path planning approaches in many cases. Furthermore, it naturally extends to semantically specified goals, such as 'going to a chair'. We also deploy CMP on physical robots in indoor environments, where it achieves reasonable performance, even though it is trained entirely in simulation. \nCitations 27\nReferences 9\nDegree 36\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}